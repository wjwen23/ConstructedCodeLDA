{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 21832/21832 [00:00<00:00, 949571.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21832/21832 [00:02<00:00, 9160.59it/s]\n",
      "  3%|██▎                                                                         | 678/21832 [00:00<00:03, 6581.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['encode', 'data', 'capacity', 'length', 'string', 'builder', 'bit', 'index', 'bits', 'extract', 'append']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 21832/21832 [00:02<00:00, 10685.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]]\n",
      "21832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=12, coherence:0.5851921175620755\n",
      "best model: k=12\n",
      "[0.5851921175620755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # 将class作为文档 进行LDA\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from tqdm import tqdm\n",
    "    import json\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pprint import pprint\n",
    "\n",
    "    # Gensim\n",
    "    import gensim\n",
    "    import gensim.corpora as corpora\n",
    "    from gensim.utils import simple_preprocess\n",
    "    from lda_model_modify import modify_lda_inference\n",
    "\n",
    "    modify_lda_inference()\n",
    "    from gensim.models import CoherenceModel\n",
    "\n",
    "    # spacy for lemmatization\n",
    "    import spacy\n",
    "\n",
    "    # Plotting tools\n",
    "    import pyLDAvis\n",
    "    import pyLDAvis.gensim  # don't skip this\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "\n",
    "    matplotlib.use('TkAgg')\n",
    "\n",
    "    #     plt.switch_backend('agg')\n",
    "\n",
    "    # get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "    # Enable logging for gensim - optional\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        filename='topic.log',\n",
    "        filemode='a'\n",
    "    )\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "    # # 代码相关预处理\n",
    "    #\n",
    "    # 根据官方文档扩展代码关键词\n",
    "    # https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html\n",
    "    #\n",
    "    # ```json\n",
    "    # [\"abstract\",\"continue\",\"for\",\"new\",\"switch\",\"assert\",\"default\",\"goto\",\"package\",\"synchronized\",\"boolean\",\"do\",\"if\",\"private\",\"this\",\"break\",\"double\",\"implements\",\"protected\",\"throw\",\"byte\",\"else\",\"import\",\"public\",\"throws\",\"case\",\"enum\",\"instanceof\",\"return\",\"transient\",\"catch\",\"extends\",\"int\",\"short\",\"try\",\"char\",\"final\",\"interface\",\"static\",\"void\",\"class\",\"finally\",\"long\",\"strictfp\",\"volatile\",\"const\",\"float\",\"native\",\"super\",\"while\"]\n",
    "    # ```\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    stop_words = []\n",
    "    code_keywords = [\"abstract\", \"continue\", \"for\", \"new\", \"switch\", \"assert\", \"default\", \"goto\", \"package\",\n",
    "                     \"synchronized\", \"boolean\", \"do\", \"if\", \"private\", \"this\", \"break\", \"double\", \"implements\",\n",
    "                     \"protected\", \"throw\", \"byte\", \"else\", \"import\", \"public\", \"throws\", \"case\", \"enum\", \"instanceof\",\n",
    "                     \"return\", \"transient\", \"catch\", \"extends\", \"int\", \"short\", \"try\", \"char\", \"final\", \"interface\",\n",
    "                     \"static\", \"void\", \"class\", \"finally\", \"long\", \"strictfp\", \"volatile\", \"const\", \"float\", \"native\",\n",
    "                     \"super\", \"while\"]\n",
    "    stop_words.extend(code_keywords)\n",
    "\n",
    "    # 加载类数据\n",
    "    # path_to_token_train= \"./total_data/processed_data/tokenized_classes_train.token\"\n",
    "    # path_to_token_train = \"rawcode_comment.token\"\n",
    "    path_to_token_train = \"C://Users/Thinkpad/Desktop/tokenresult.txt\"\n",
    "\n",
    "\n",
    "    def load_token_data(path_to_token_train):\n",
    "        data = []\n",
    "        with open(path_to_token_train, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in tqdm(lines):\n",
    "                # item = json.loads(line)\n",
    "                # vocabinfo = line.split(\"+\")\n",
    "                # print(vocabinfo[0])\n",
    "\n",
    "                data.append(line)\n",
    "        return data\n",
    "\n",
    "\n",
    "    data = load_token_data(path_to_token_train)\n",
    "\n",
    "\n",
    "    # 这里用到了gensim.utils.simple_preprocess,会自动将太长和太短的词过滤掉, 比如x,y, 比如0,1\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    def sent_to_words(sentences):\n",
    "        for sentence in tqdm(sentences):\n",
    "            yield (gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "\n",
    "    data_words = list(sent_to_words(data))\n",
    "    print(data_words[:1])\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "    def remove_stopwords(texts):\n",
    "        return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in tqdm(texts)]\n",
    "\n",
    "\n",
    "    # Remove Stop Words\n",
    "    data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words_nostops)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_words_nostops\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # View\n",
    "    print(corpus[:1])\n",
    "    print(len(corpus))\n",
    "\n",
    "    # serialize the corpus\n",
    "    corpora.MmCorpus.serialize('lda_classes_token_train.mm', corpus)\n",
    "\n",
    "    # and reload it!\n",
    "    corpus = gensim.corpora.MmCorpus(\"lda_classes_token_train.mm\")\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    def train_lda_model(dictionary, corpus, texts, limit, start=2, step=3, epoch=5):\n",
    "        \"\"\"\n",
    "        Compute c_v coherence for various number of topics\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        best_model : Best of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "        \"\"\"\n",
    "        coherence_values = []\n",
    "        best_value = 0.0\n",
    "        for num_topics in tqdm(range(start, limit, step)):\n",
    "            # - emm, do not use multicore...\n",
    "            #         model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,id2word=id2word,num_topics=num_topics,\n",
    "            #                                                         random_state=100,chunksize=100,passes=2,\n",
    "            #                                                         per_word_topics=True,workers=2)\n",
    "            model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=num_topics,\n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=1000,\n",
    "                                                    passes=epoch,\n",
    "                                                    iterations=2,\n",
    "                                                    alpha='auto',\n",
    "                                                    per_word_topics=True)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_value = coherencemodel.get_coherence()\n",
    "            print(\"k=\" + str(num_topics) + \", coherence:\" + str(coherence_value))\n",
    "            if coherence_value > best_value:\n",
    "                print(\"best model: k=\" + str(num_topics))\n",
    "                best_value = coherence_value\n",
    "                best_model = model\n",
    "            model.save('lda_models_' + str(num_topics) + '_epoch=' + str(\n",
    "                epoch) + '_chunk=' + str(1000) + '.model')\n",
    "            coherence_values.append(coherence_value)\n",
    "        return best_model, coherence_values\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "    limit = 13\n",
    "    start = 12\n",
    "    step = 1\n",
    "    epoch = 5\n",
    "\n",
    "    # 训练并获得最优评估值模型\n",
    "    lda_model, coherence_values = train_lda_model(dictionary=id2word, corpus=corpus, texts=data_words_nostops,\n",
    "                                                  start=start, limit=limit, step=step, epoch=epoch)\n",
    "\n",
    "    print(coherence_values)\n",
    "\n",
    "    # # # In[ ]:\n",
    "\n",
    "    # # Show graph\n",
    "    # x = range(start, limit, step)\n",
    "    # plt.plot(x, coherence_values)\n",
    "    # plt.xlabel(\"Num Topics\")\n",
    "    # plt.ylabel(\"Coherence score\")\n",
    "    # plt.legend((\"coherence_values\"), loc='best')\n",
    "    # plt.show()\n",
    "    # plt.savefig('topicnum_coherence.png', bbox_inches='tight')\n",
    "    # Visualize the topics\n",
    "    # pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    pyLDAvis.save_html(vis, 'lda.html')\n",
    "    # pyLDAvis.show(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "    vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    pyLDAvis.save_html(vis, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Dec/2019 10:51:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2019 10:51:06] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2019 10:51:06] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2019 10:51:06] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "    pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(top)? (<ipython-input-7-76d9e2622195>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-76d9e2622195>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print top\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(top)?\n"
     ]
    }
   ],
   "source": [
    "for top in lda_model.print_topics(10):\n",
    "  print (top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
